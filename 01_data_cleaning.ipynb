{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import datetime as dt\n",
    "from plotnine import * # Implementation of ggplot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "\n",
    "- King County Housing Data.\n",
    "- House Sales from King-County, WA, USA from May 2014 to May 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs = pd.read_csv(\"./data/king_county_houses_sales.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect the data\n",
    "1. Meaningful column names in standard forms (lower-case, no whitespaces?)?\n",
    "2. Right data types for all columns?\n",
    "3. correct SI-Units?\n",
    "4. Duplicates? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Column Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. Show the column names\n",
    "df_hs.columns\n",
    "\n",
    "### Create a dictionary for df.rename() \n",
    "### Shorten a few columns, define better, more easily understandable names and change area to m^2\n",
    "new_names = {'id':'id_house', \n",
    "            'bedrooms':'n_bedr', \n",
    "            'bathrooms': 'n_bathr', \n",
    "            'sqft_living': 'a_living_sqm', \n",
    "            'sqft_lot': 'a_lot_sqm',\n",
    "            'floors': 'n_floors',\n",
    "            'sqft_above': 'a_above_sqm',\n",
    "            'sqft_basement': 'a_basem_sqm', \n",
    "            'view': 'inspected', \n",
    "            'sqft_living15': 'a_living_15_sqm', \n",
    "            'sqft_lot15': 'a_lot_15_sqm',\n",
    "            'date': 'date_sold'}\n",
    "\n",
    "### Apply rename with the dictionary variable for changing column names\n",
    "df_hs.rename(new_names, axis = 1, inplace = True)\n",
    "df_hs.columns\n",
    "\n",
    "### Clear workspace of new_names\n",
    "del new_names\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Check the data-types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Right Data types?\n",
    "df_hs.shape\n",
    "\n",
    "#   date_sold to be changed into date\n",
    "df_hs.date_sold = pd.to_datetime(df_hs.date_sold)\n",
    "#   yr_renovated numeric but should be as integer or date\n",
    "df_hs.yr_renovated.sort_values().unique() # either 0, 19340 >= <= 20150 always with last digit 0 or nan\n",
    "#   Thus divide by 10 to convert to years and to int\n",
    "df_hs.yr_renovated = df_hs.yr_renovated / 10\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean yr_renovated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "### Function to differentiate btween 0, NaN and valid year values\n",
    "df_hs.yr_renovated.sort_values().unique()\n",
    "def group_year(x): \n",
    "    if pd.isna(x):\n",
    "        return \"NaN\"\n",
    "    elif x == 0:\n",
    "        return \"0\"\n",
    "    else:\n",
    "        return \"Valid year\"\n",
    "\n",
    "### Copy the dataframe\n",
    "df_hs_2 = df_hs\n",
    "\n",
    "### Create a column which defines wether yr_renovated has a NaN value, a 0 value or a valid year\n",
    "df_hs_2[\"val_yr_renov\"] = df_hs.yr_renovated.apply(group_year)\n",
    "\n",
    "### Plot a histogram for each of the class to determine, wether 0 and NaN depend on the year the house was built\n",
    "fig = px.histogram(df_hs_2, x = \"yr_built\", \n",
    "                    facet_row = \"val_yr_renov\",\n",
    "                    color = \"val_yr_renov\")\n",
    "fig.update_yaxes(matches=None)\n",
    "fig.show()\n",
    "\n",
    "del df_hs_2\n",
    "del group_year\n",
    "\n",
    "### Assign a NaN to yr_renovated where it is 0\n",
    "df_hs.yr_renovated = df_hs.yr_renovated.replace(0, np.nan, inplace = False)\n",
    "\n",
    "### As String - creates 'nan' instead of nan\n",
    "df_hs.yr_renovated = df_hs.yr_renovated.astype(\"str\").str.replace(\".0\", \"\", regex = False)\n",
    "\n",
    "### cast 'nan' back to nan\n",
    "df_hs.yr_renovated = df_hs.yr_renovated.replace(\"nan\", np.nan)\n",
    "\n",
    "### cast back to float. Int does not include the NaN\n",
    "df_hs.yr_renovated = df_hs.yr_renovated.astype(\"float\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Only valid years in yr_renovated show a meaningful pattern - most houses built after 1980 have not been renovated since\n",
    "- while 0 and NaN values follow the distribution of the whole dataset show the same pattern, only in different numbers\n",
    "- If one of these two were to represent renovated houses with the year of renovation unknown, a different pattern could be expected, independent of the overall pattern of houses built"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect yr_build\n",
    "- No missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect yr_build\n",
    "px.histogram(df_hs, x = \"yr_built\") # seems to make sense\n",
    "df_hs.yr_built.unique() # No missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Correct SI Units?\n",
    "- Convert Area columns to m^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area columns to sqm\n",
    "ind = df_hs.columns.str.contains(\"_sqm$\", regex = True)\n",
    "df_hs.loc[:,ind] = df_hs.loc[:,ind].apply(lambda x: x/10.764).round(2)\n",
    "df_hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values of area - outliers etc?\n",
    "df_areas = df_hs.loc[:,ind].melt() ### all area columns melted into long format for easier plotting\n",
    "\n",
    "p1 = ggplot (df_areas, aes (x = \"value\")) + \\\n",
    "    geom_freqpoly() + \\\n",
    "    facet_wrap (\"variable\", ncol = 2, scales = \"free\") + \\\n",
    "    theme(panel_spacing = 0.3)\n",
    "ggsave (p1, \"./plots/area_histograms.png\", dpi = 150)\n",
    "\n",
    "### Overview of the distributon parameters of areas. Looks reasonable and also interested in lower values\n",
    "df_hs.loc[:,ind].describe()\n",
    "\n",
    "del df_areas\n",
    "del ind"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data of all area columns looks reasonable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Duplicates?\n",
    "- For duplicated sells: exclude earlier sell of house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For duplicated sells: exclude earlier sell of house\n",
    "### With drop duplicates after sort_values by sale date\n",
    "df_hs_2 = df_hs.sort_values(by = \"date_sold\", ascending = False)\n",
    "\n",
    "df_hs_2.drop_duplicates(subset = \"id_house\", keep = \"first\", inplace = True)\n",
    "df_hs_2.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the cleaned data frame for later use\n",
    "df_hs_2.to_pickle(\"./data/df_houses_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hs_2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8 (main, Jan  9 2023, 15:57:35) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ce94bdfc54693336f2ba42aa87a7cd0f0c4e0845b78939f0948bf4cf6add902"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
